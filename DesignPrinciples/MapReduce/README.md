## Two main Hadoop components
* HDFS - Storage built over Hbase.
* Map Reduce - For processing.

## Map Reduce Overivew
* This helps in processing data parallely in distributed environment.
* Example: Process Big Data on hadoop HDFS --> Map Reduce --> Result.
* Why do we need Map Reduce for this? It is because the Big Data stored in HDFS is stored as chunks in different data Nodes. The data does not reside in one single location like a traditional RDBMS.

![mr applications](https://user-images.githubusercontent.com/6800366/41507074-890576a6-7248-11e8-8104-54db29967a12.PNG)


